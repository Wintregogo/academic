# app.py
import streamlit as st
import yaml
import os
import pandas as pd
from datetime import datetime
from utils import load_config
from main_streamlit import streaming_run_analysis

# ======================
# é¡µé¢åˆå§‹åŒ–
# ======================

# åŠ è½½é»˜è®¤é…ç½®
DEFAULT_CONFIG = load_config("config.yaml")

st.set_page_config(
    page_title="arXiv Insight",
    page_icon="ğŸ”",
    layout="wide"
)

st.title("ğŸ” arXiv é¢„å°æœ¬æ™ºèƒ½åˆ†æç³»ç»Ÿ")
st.markdown("è¾“å…¥å…³é”®è¯ï¼Œè‡ªåŠ¨è·å–æœ€æ–°è®ºæ–‡å¹¶ç”± LLM è¯„åˆ†ã€æå–äº®ç‚¹")

# åˆå§‹åŒ– session state
if "show_all_papers" not in st.session_state:
    st.session_state.show_all_papers = False
if "analysis_results" not in st.session_state:
    st.session_state.analysis_results = None

# ======================
# ä¾§è¾¹æ ï¼šé…ç½®å‚æ•°
# ======================

with st.sidebar:
    st.header("âš™ï¸ é…ç½®å‚æ•°")

    # æŸ¥è¯¢å‚æ•°
    default_keywords = ", ".join(DEFAULT_CONFIG.get("query", {}).get("keywords", ["large language models"]))
    keywords = st.text_input("å…³é”®è¯ï¼ˆè‹±æ–‡ï¼Œé€—å·åˆ†éš”ï¼‰", value=default_keywords)

    default_cats = DEFAULT_CONFIG.get("query", {}).get("categories", ["cs.CL", "cs.AI"])
    categories = st.multiselect(
        "å­¦ç§‘åˆ†ç±»",
        options=["cs.CL", "cs.AI", "cs.LG", "cs.CV", "stat.ML", "physics.comp-ph"],
        default=default_cats
    )

    default_days = DEFAULT_CONFIG.get("query", {}).get("time_window_days", 7)
    days = st.slider("æ—¶é—´çª—å£ï¼ˆå¤©ï¼‰", 1, 30, default_days)

    default_topk = DEFAULT_CONFIG.get("query", {}).get("top_k", 5)
    top_k = st.slider("è¿”å›ç¯‡æ•°ï¼ˆTop Kï¼‰", 1, 20, default_topk)

    # ä½œè€…ä¿¡æ¯
    author_cfg = DEFAULT_CONFIG.get("features", {}).get("author_info", {})
    use_author_info = st.checkbox(
        "å¯ç”¨ä½œè€…ä¿¡æ¯ï¼ˆSemantic Scholar / OpenAlexï¼‰",
        value=author_cfg.get("enabled", False)
    )
    
    default_sources = author_cfg.get("sources", ["semantic_scholar", "openalex"])
    author_sources = []
    if use_author_info:
        author_sources = st.multiselect(
            "ä½œè€…æ•°æ®æºï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰",
            options=["semantic_scholar", "openalex"],
            default=[s for s in default_sources if s in ["semantic_scholar", "openalex"]]
        )

    # è§£æå™¨
    parser_cfg = DEFAULT_CONFIG.get("parser", {})
    use_grobid = parser_cfg.get("use_grobid", False)
    grobid_url = parser_cfg.get("grobid_url", "http://localhost:8070")
    use_grobid = st.checkbox("ä½¿ç”¨ Grobid è§£æ PDF", value=use_grobid)

    # LLM è®¾ç½®
    llm_cfg = DEFAULT_CONFIG.get("llm", {})
    llm_provider = st.selectbox("æ¨¡å‹æä¾›å•†", ["qwen"], index=0)
    default_model = llm_cfg.get("model", "qwen-plus")
    model_options = ["qwen-turbo", "qwen-plus", "qwen-max"]
    model_index = model_options.index(default_model) if default_model in model_options else 1
    llm_model = st.selectbox("æ¨¡å‹", model_options, index=model_index)
    api_key = st.text_input("DashScope API Key", type="password", value=llm_cfg.get("api_key", ""))

    output_cfg = DEFAULT_CONFIG.get("output", {})
    report_path = output_cfg.get("report_path", "export/report.md")
    csv_path = output_cfg.get("csv_path", "export/report.csv")
    json_path = output_cfg.get("json_path", "export/report.json")

    run_btn = st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary")

# ======================
# ä¸»é€»è¾‘ï¼šæµå¼åˆ†æ + åŠ¨æ€æ›´æ–°
# ======================

if run_btn:
    if not api_key.strip():
        st.error("è¯·å¡«å†™ DashScope API Key")
    else:
        # æ„å»ºæœ€ç»ˆé…ç½®
        config = {
            "query": {
                "keywords": [k.strip() for k in keywords.split(",") if k.strip()],
                "categories": categories,
                "time_window_days": days,
                "top_k": top_k
            },
            "llm": {
                "provider": llm_provider,
                "model": llm_model,
                "api_key": api_key
            },
            "parser": {
                "use_grobid": use_grobid,
                "grobid_url": grobid_url
            },
            "output": {
                "report_path": report_path,
                "csv_path": csv_path,
                "json_path": json_path
            },
            "features": {
                "author_info": {
                    "enabled": use_author_info,
                    "sources": author_sources if use_author_info else []
                }
            }
        }

        # åˆ›å»ºå®¹å™¨
        status_container = st.empty()
        results_container = st.empty()
        download_container = st.empty()
        progress_bar = st.progress(0)

        all_results = []

        # æµå¼åˆ†æè¿‡ç¨‹
        with st.spinner("æ­£åœ¨åˆ†æè®ºæ–‡..."):
            try:
                for partial_results, total_papers in streaming_run_analysis(config):
                    all_results = partial_results
                    analyzed = len(partial_results)

                    if total_papers > 0:
                        if analyzed == total_papers:
                            # åˆ†æå®Œæˆ
                            status_container.success(f"âœ… åˆ†æå®Œæˆï¼å…±å¤„ç† {total_papers} ç¯‡è®ºæ–‡")
                        else:
                            # æ˜¾ç¤ºå¸¦è¿›åº¦æ¡çš„çŠ¶æ€
                            progress = min(analyzed / total_papers, 1.0)
                            with status_container.container():
                                st.markdown(
                                    f"""
                                    <div style="display: flex; align-items: center; justify-content: space-between; padding: 10px; background-color: #1e3a8a; color: white; border-radius: 6px; margin-bottom: 10px;">
                                        <span style="font-size: 14px; font-weight: normal;">
                                            â³ å·²åˆ†æ <strong>{analyzed}</strong> / <strong>{total_papers}</strong> ç¯‡è®ºæ–‡ï¼Œ...
                                        </span>
                                        <div style="width: 200px; height: 10px; background-color: #d1d5da; border-radius: 5px; overflow: hidden;">
                                            <div style="width: {int(progress * 100)}%; height: 100%; background-color: #3b82f6; transition: width 0.3s;"></div>
                                        </div>
                                    </div>
                                    """,
                                    unsafe_allow_html=True
                                )
                    else:
                        progress_bar.empty()
                        status_container.info("æ²¡æœ‰æ‰¾åˆ°è®ºæ–‡")

                    # === æµå¼é˜¶æ®µï¼šä»…æ˜¾ç¤º Top K æ ‡é¢˜ï¼ˆä¸å±•å¼€ï¼‰===
                    display_papers = sorted(
                        partial_results,
                        key=lambda x: x.get("final_score", 0),
                        reverse=True
                    )[:top_k]

                    results_container.empty()
                    with results_container.container():
                        for i, paper in enumerate(display_papers):
                            st.markdown(
                                f"### {i+1}. [{paper['title']}](https://arxiv.org/abs/{paper['id']})"
                            )
                            # ğŸ”§ ä¿®å¤ï¼šf-string ä¸­ä¸èƒ½ç›´æ¥ç”¨åŒå¼•å·ï¼Œæ”¹ç”¨å•å¼•å·æˆ–è½¬ä¹‰
                            st.caption(
                                f"å‘è¡¨æ—¶é—´: {paper['published'][:10]} | "
                                f"åˆ†æ•°: {paper.get('final_score', 0):.2f}"
                            )

            except Exception as e:
                status_container.error(f"åˆ†æå‡ºé”™: {str(e)}")
                st.exception(e)
                raise

        # ä¿å­˜ç»“æœåˆ° session state
        if all_results:
            st.session_state.analysis_results = all_results

        results_container.empty()


# ======================
# æ¸²æŸ“æœ€ç»ˆç»“æœï¼ˆæ— è®ºæ˜¯å¦åˆšè¿è¡Œï¼‰
# ======================

if st.session_state.analysis_results is not None:
    all_results = st.session_state.analysis_results
    sorted_papers = sorted(all_results, key=lambda x: x.get("final_score", 0), reverse=True)

    # å†³å®šæ˜¾ç¤ºèŒƒå›´
    if st.session_state.show_all_papers:
        papers_to_display = sorted_papers
        btn_label = "â¬†ï¸ æ”¶èµ·ï¼ˆä»…æ˜¾ç¤º Top 5ï¼‰"
    else:
        papers_to_display = sorted_papers[:top_k]
        btn_label = f"ğŸ” æ˜¾ç¤ºå…¨éƒ¨ {len(sorted_papers)} ç¯‡è®ºæ–‡"

    col_btn, _ = st.columns([1, 3])
    with col_btn:
        if st.button(btn_label, key="toggle_show_all_final"):
            st.session_state.show_all_papers = not st.session_state.show_all_papers
            st.rerun()

    # æ¸²æŸ“æœ€ç»ˆè®ºæ–‡ï¼ˆä½¿ç”¨é›¶å®½ç©ºæ ¼ç¡®ä¿ expander å”¯ä¸€ï¼‰
    for i, paper in enumerate(papers_to_display):
        rank = i + 1
        # \u200b æ˜¯é›¶å®½ç©ºæ ¼ï¼Œç”¨æˆ·çœ‹ä¸è§ï¼Œä½†ä½¿æ ‡é¢˜å”¯ä¸€
        unique_title = f"{rank}. {paper['title']}\u200b(arXiv:{paper['id']})"
        with st.expander(unique_title, expanded=(i == 0 and not st.session_state.show_all_papers)):
            col1, col2 = st.columns([2, 1])
            with col1:
                st.markdown(f"**å‘è¡¨æ—¶é—´**: {paper['published'][:10]}")
                st.markdown(f"**åˆ†æ•°**: `{paper.get('final_score', 0)}` (åŸºç¡€: `{paper.get('total_score', 0)}`, äº®ç‚¹: `{paper.get('insight_bonus', 0)}`)")
                st.markdown(f"**è¯­è¨€**: {'ä¸­æ–‡' if paper.get('language') == 'zh' else 'English'}")
                st.markdown(f"[æŸ¥çœ‹å…¨æ–‡](https://arxiv.org/abs/{paper['id']}) | [PDF](https://arxiv.org/pdf/{paper['id']})")

                if paper.get("authors_info"):
                    st.markdown("**ä½œè€…ä¿¡æ¯**:")
                    for author in paper["authors_info"]:
                        name = author.get("name", "N/A")
                        hindex = author.get("h_index", "N/A")
                        org = author.get("affiliations", ["N/A"])[0] if author.get("affiliations") else "N/A"
                        source = author.get("source_used", "")
                        st.caption(f"- {name} | H-index: {hindex} | {org} ({source})")

                st.markdown("**æ‘˜è¦**:")
                st.write(paper["abstract"])
                st.markdown("**ğŸ’¡ äº®ç‚¹**:")
                st.write(paper["breakthrough"])
                st.markdown("### ğŸŒ è¯‘æ–‡ï¼ˆAbstract Translationï¼‰")
                st.text(paper.get("translation", "æš‚æ— è¯‘æ–‡"))
                st.markdown("### ğŸ§  è„‘å›¾ï¼ˆMind Mapï¼‰")
                st.markdown(paper.get("mindmap_markdown", "æš‚æ— è„‘å›¾"))

            with col2:
                st.metric("åˆ›æ–°æ€§", paper.get("innovation", 0))
                st.metric("ä¸¥è°¨æ€§", paper.get("rigor", 0))
                st.metric("å½±å“åŠ›", paper.get("impact", 0))

    # ä¸‹è½½æŒ‰é’®
    df = pd.DataFrame(all_results)
    csv = df.to_csv(index=False).encode('utf-8-sig')
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½å®Œæ•´ CSV",
        data=csv,
        file_name="arxiv_insight.csv",
        mime="text/csv"
    )

else:
    st.info("ç‚¹å‡»å·¦ä¾§ã€Œå¼€å§‹åˆ†æã€æŒ‰é’®ä»¥å¯åŠ¨åˆ†ææµç¨‹ã€‚")