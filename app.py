# app.py
import streamlit as st
import yaml
import os
from datetime import datetime
from main_streamlit import run_analysis  # æˆ‘ä»¬ç¨åå®šä¹‰è¿™ä¸ªå‡½æ•°

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="arXiv Insight",
    page_icon="ğŸ”",
    layout="wide"
)

st.title("ğŸ” arXiv é¢„å°æœ¬æ™ºèƒ½åˆ†æç³»ç»Ÿ")
st.markdown("è¾“å…¥å…³é”®è¯ï¼Œè‡ªåŠ¨è·å–æœ€æ–°è®ºæ–‡å¹¶ç”± LLM è¯„åˆ†ã€æå–äº®ç‚¹")

st.subheader("ğŸ‘¥ ä½œè€…ä¿¡æ¯")
use_author_info = st.checkbox("å¯ç”¨ä½œè€…ä¿¡æ¯å¢å¼º", value=False)
author_sources = []
if use_author_info:
    author_sources = st.multiselect(
        "æ•°æ®æºï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰",
        options=["semantic_scholar", "openalex"],
        default=["semantic_scholar", "openalex"]
    )

# === ä¾§è¾¹æ é…ç½® ===
with st.sidebar:
    st.header("âš™ï¸ é…ç½®å‚æ•°")

    keywords = st.text_input("å…³é”®è¯ï¼ˆè‹±æ–‡ï¼Œé€—å·åˆ†éš”ï¼‰", "large language models, reasoning")
    categories = st.multiselect(
        "å­¦ç§‘åˆ†ç±»",
        options=["cs.CL", "cs.AI", "cs.LG", "cs.CV", "stat.ML", "physics.comp-ph"],
        default=["cs.CL", "cs.AI"]
    )
    days = st.slider("æ—¶é—´çª—å£ï¼ˆå¤©ï¼‰", 1, 30, 7)
    top_k = st.slider("è¿”å›ç¯‡æ•°", 1, 20, 5)

    use_author_info = st.checkbox("å¯ç”¨ä½œè€…ä¿¡æ¯ï¼ˆSemantic Scholarï¼‰", value=False)
    use_grobid = st.checkbox("ä½¿ç”¨ Grobid è§£æ PDFï¼ˆéœ€æœ¬åœ°è¿è¡Œï¼‰", value=False)

    st.divider()
    st.subheader("ğŸ”‘ LLM è®¾ç½®")
    llm_provider = st.selectbox("æ¨¡å‹æä¾›å•†", ["qwen"])
    llm_model = st.selectbox("æ¨¡å‹", ["qwen-turbo", "qwen-plus", "qwen-max"])
    api_key = st.text_input("DashScope API Key", type="password")

    run_btn = st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary")

# === ä¸»ç•Œé¢ ===
if run_btn:
    if not api_key:
        st.error("è¯·å¡«å†™ DashScope API Key")
    else:
        # æ„å»º config å­—å…¸ï¼ˆæ›¿ä»£ config.yamlï¼‰
        config = {
            "features": {
                "author_info": {
                    "enabled": use_author_info,
                    "sources": author_sources
                }
            },
            "query": {
                "keywords": [k.strip() for k in keywords.split(",") if k.strip()],
                "categories": categories,
                "time_window_days": days,
                "top_k": top_k
            },
            "llm": {
                "provider": llm_provider,
                "model": llm_model,
                "api_key": api_key
            },
            "parser": {
                "use_grobid": use_grobid,
                "grobid_url": "http://localhost:8070"
            },
            "output": {
                "report_path": "report.md"
            }
        }

        with st.spinner("æ­£åœ¨åˆ†æè®ºæ–‡...ï¼ˆå¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰"):
            try:
                results = run_analysis(config)
                st.success(f"âœ… åˆ†æå®Œæˆï¼å…±å¤„ç† {len(results)} ç¯‡è®ºæ–‡")

                # æ˜¾ç¤ºç»“æœ
                for i, paper in enumerate(results):
                    with st.expander(f"{i+1}. {paper['title']}", expanded=(i == 0)):
                        col1, col2 = st.columns([2, 1])
                        with col1:
                            st.markdown(f"**å‘è¡¨æ—¶é—´**: {paper['published'][:10]}")
                            st.markdown(f"**åˆ†æ•°**: `{paper.get('final_score', 0)}` (åŸºç¡€: `{paper.get('total_score', 0)}`, äº®ç‚¹åŠ æˆ: `{paper.get('insight_bonus', 0)}`)")
                            st.markdown(f"**è¯­è¨€**: {'ä¸­æ–‡' if paper.get('language') == 'zh' else 'English'}")
                            st.markdown(f"[æŸ¥çœ‹å…¨æ–‡](https://arxiv.org/abs/{paper['id']}) | [PDF](https://arxiv.org/pdf/{paper['id']})")
                            
                            if paper.get("authors_info"):
                                st.markdown("**ä½œè€…ä¿¡æ¯**:")
                                for author in paper["authors_info"]:
                                    name = author.get("name", "N/A")
                                    hindex = author.get("hIndex", "N/A")
                                    org = author.get("affiliations", ["N/A"])[0] if author.get("affiliations") else "N/A"
                                    st.caption(f"- {name} | H-index: {hindex} | {org}")

                            st.markdown("**æ‘˜è¦**:")
                            st.write(paper["abstract"])
                            st.markdown("**ğŸ’¡ äº®ç‚¹**:")
                            st.write(paper["breakthrough"])

                        with col2:
                            st.metric("åˆ›æ–°æ€§", paper.get("innovation", 0))
                            st.metric("ä¸¥è°¨æ€§", paper.get("rigor", 0))
                            st.metric("å½±å“åŠ›", paper.get("impact", 0))

                # æä¾›ä¸‹è½½
                import pandas as pd
                df = pd.DataFrame(results)
                csv = df.to_csv(index=False).encode('utf-8-sig')
                st.download_button("ğŸ“¥ ä¸‹è½½ CSV", csv, "arxiv_insight.csv", "text/csv")

            except Exception as e:
                st.error(f"åˆ†æå‡ºé”™: {str(e)}")
                st.exception(e)
else:
    st.info("ç‚¹å‡»å·¦ä¾§ã€Œå¼€å§‹åˆ†æã€æŒ‰é’®ä»¥å¯åŠ¨åˆ†ææµç¨‹ã€‚")